{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FTBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AIz6uBJ4LAgPB4AkK5rvyiw1iYrDmY1x",
      "authorship_tag": "ABX9TyPbDlq9VIv4nEgTnf9se/gT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasuff/Vies-de-genero-em-PLN-em-portugues/blob/main/FTBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhew5QerXZOi",
        "outputId": "c8c77bf8-4578-49c1-e099-652fbcd5ce0f"
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLIQ7WLKXngB"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PNSHe3BXtQw",
        "outputId": "b11a2503-53db-4b36-c3d9-0b2815563931"
      },
      "source": [
        "model = BertModel.from_pretrained('/content/drive/MyDrive/curso_word2vec/bertFineTunedWomanModel', output_hidden_states = True)\n",
        "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=False, never_split=['lol'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/curso_word2vec/bertFineTunedWomanModel were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qpJL8ir0_nX"
      },
      "source": [
        "def generate_embeddings(text):\n",
        "  try:\n",
        "    # Add the special tokens.\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "    # Split the sentence into tokens.\n",
        "    tokenizer.add_tokens('lol')\n",
        "    tokenized_text = tokenizer.basic_tokenizer.tokenize(marked_text)\n",
        "\n",
        "    # Map the token strings to their vocabulary indeces.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers. \n",
        "    with torch.no_grad():\n",
        "      outputs = model(tokens_tensor, segments_tensors)\n",
        "      # Evaluating the model will return a different number of objects based on \n",
        "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "      # becase we set `output_hidden_states = True`, the third item will be the \n",
        "      # hidden states from all layers. See the documentation for more details:\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "    # Remove dimension 1, the \"batches\".\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "    # Swap dimensions 0 and 1.\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # Stores the token vectors, with shape [22 x 768]\n",
        "    token_vecs_sum = []\n",
        "\n",
        "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        # `token` is a [12 x 768] tensor\n",
        "\n",
        "        # Sum the vectors from the last four layers.\n",
        "        sum_vec = torch.sum(token[-4:], dim=0)\n",
        "        \n",
        "        # Use `sum_vec` to represent `token`.\n",
        "        token_vecs_sum.append(sum_vec)\n",
        "      \n",
        "    return [tokenized_text[3]], [token_vecs_sum[3]]\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return None, None\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8F6L_bWyaps"
      },
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "file = open(\"/content/drive/MyDrive/curso_word2vec/contents_woman.json\", \"r\")\n",
        "trip_contents = json.load(file)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvClU25J1GUD"
      },
      "source": [
        "vocabulary = json.load(open(\"/content/drive/MyDrive/curso_word2vec/vocabulary.json\", \"r\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dv24z3Fxnus"
      },
      "source": [
        "tokenized_text = []\n",
        "token_vecs_sum = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkx_iBVByfb1",
        "outputId": "590a4698-3e81-44b7-b032-86dcdf1c9427"
      },
      "source": [
        "for word in vocabulary:\n",
        "    temp_tokenized_text, temp_token_vecs_sum = generate_embeddings(word)\n",
        "    if temp_tokenized_text and temp_token_vecs_sum:\n",
        "      tokenized_text += temp_tokenized_text\n",
        "      token_vecs_sum += temp_token_vecs_sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index out of range in self\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbwPuY1d0_no"
      },
      "source": [
        "def get_word_vector(word):\n",
        "  for i in range(0, len(tokenized_text)):\n",
        "    if tokenized_text[i]==word:\n",
        "      return token_vecs_sum[i]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDVIUuSH0_np"
      },
      "source": [
        "def print_closest_words(pos1, pos2=None, neg=None, n=5):\n",
        "    vec = get_word_vector(pos1)\n",
        "    if pos2:\n",
        "      vec = vec + get_word_vector(pos2)\n",
        "    if neg:\n",
        "      vec = vec - get_word_vector(neg)\n",
        "    dists = torch.norm(torch.stack(token_vecs_sum) - vec, dim=1)     # compute distances to all words\n",
        "    lst = sorted(enumerate(dists.numpy()), key=lambda x: x[1]) # sort by distance\n",
        "    results = {}\n",
        "    for idx, difference in lst[1:n+1]:                         # take the top n\n",
        "        if tokenized_text[idx]!=pos2 and tokenized_text[idx]!=pos1 and tokenized_text[idx]!=neg and tokenized_text[idx] not in results:\n",
        "          results[tokenized_text[idx]] = difference\n",
        "\n",
        "    for key in results:\n",
        "      print(key, results[key])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNU3HFZt0_np",
        "outputId": "7d8f65e7-85ae-415d-d1fd-9a553509138f"
      },
      "source": [
        "print_closest_words(\"mulher\", \"rei\", \"homem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "monarca 62.72767\n",
            "reis 64.24586\n",
            "imperador 67.26562\n",
            "princesa 67.38791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvvlyR9F0_np",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0659a136-0bc2-4570-e970-cff8f64e60fb"
      },
      "source": [
        "print_closest_words(\"homem\", \"rainha\", \"mulher\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rei 54.17106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX27ihul0_nq"
      },
      "source": [
        "print_closest_words(\"homem\", \"chefe\", \"mulher\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl6Pns2m0_nq",
        "outputId": "03f653b8-d7aa-4341-89cb-c5290734d494"
      },
      "source": [
        "print_closest_words(\"mulher\", \"chefe\", \"homem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chefes 67.98172\n",
            "chefia 68.10663\n",
            "líder 69.14633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDyg2WWm0_nq"
      },
      "source": [
        "print_closest_words(\"homem\", \"professora\", \"mulher\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn2lnPyg0_nr",
        "outputId": "eeb1c6e2-4992-4e60-c7cb-5d1370ad8b79"
      },
      "source": [
        "print_closest_words(\"mulher\", \"professor\", \"homem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "professora 58.252575\n",
            "professores 62.69785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQNUQvQX0_nr",
        "outputId": "66d4df90-4266-4436-fae4-1358021c316d"
      },
      "source": [
        "print_closest_words(\"mulher\", \"médico\", \"homem\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "médica 56.881596\n",
            "médicos 63.81574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deAAMkFUuF4f",
        "outputId": "4afedbbb-798f-440d-de48-e7d938931b18"
      },
      "source": [
        "print_closest_words(\"rainha\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "princesa 39.87251\n",
            "duquesa 43.915356\n",
            "rei 43.948284\n",
            "príncipe 44.116882\n",
            "monarca 46.287426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRDPLDsbugg8",
        "outputId": "bc664134-507f-4593-cab3-7a4d9c5f6866"
      },
      "source": [
        "print_closest_words(\"rei\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reis 39.189095\n",
            "rainha 43.948284\n",
            "monarca 44.058426\n",
            "príncipe 45.222347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_39ERI5Dum0N",
        "outputId": "a5746f7b-0447-4623-d917-a2bc9825dae5"
      },
      "source": [
        "print_closest_words(\"chefe\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chefes 30.992754\n",
            "líder 38.577938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmCnMemfutkv",
        "outputId": "94ff7333-0e5d-42ce-8671-fed6d40e3949"
      },
      "source": [
        "print_closest_words(\"dermatologista\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "erghbal 0.0\n",
            "irã 0.0\n",
            "iraniana 0.0\n",
            "desembarcaram 0.0\n",
            "unido 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asAomjNnwzF-"
      },
      "source": [
        "print_closest_words(\"mulher\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJBKGCNVw1L3"
      },
      "source": [
        "print_closest_words(\"homem\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_H1PHT9w2rs",
        "outputId": "381aca1f-0936-4052-e960-973a826df9fe"
      },
      "source": [
        "print_closest_words(\"esposa\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "marido 38.3694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zU7HhQ3zDvd",
        "outputId": "0a27279c-f5ae-4f57-ac49-e92b9c9efe11"
      },
      "source": [
        "print_closest_words(\"tio\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tia 39.385933\n",
            "sobrinha 41.94717\n",
            "sobrinho 44.56737\n",
            "avô 45.707752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJg0GjmSzFWI",
        "outputId": "cea56651-32cd-4bde-e242-291d08b6078f"
      },
      "source": [
        "print_closest_words(\"tia\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tio 39.385933\n",
            "sobrinha 40.23784\n",
            "avó 44.076557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hGQb298zH6I"
      },
      "source": [
        "print_closest_words(\"marido\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xat3OqNIzKJi",
        "outputId": "453ff702-456a-46ad-ccd2-be80ac20662a"
      },
      "source": [
        "print_closest_words(\"chefe\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chefes 30.992754\n",
            "líder 38.577938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN6ROGLiyNXt",
        "outputId": "5544ed40-dcb9-4ce8-cb1a-0f71426760ba"
      },
      "source": [
        "print_closest_words(\"legal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "legais 34.142735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_vecs_sum_t = torch.stack((token_vecs_sum))\n"
      ],
      "metadata": {
        "id": "qQrXmr44Qw5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(token_vecs_sum_t, \"/content/drive/MyDrive/curso_word2vec/BertEmbeddings/BertFinetunedTorches.json\")"
      ],
      "metadata": {
        "id": "sez8yYNmQdGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(token_vecs_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYL77ZjYQaMc",
        "outputId": "c9dc479d-19ba-4cbf-e98e-4112a1a88707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158368"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr-orjZ0bjDu",
        "outputId": "9eaeda4b-85d4-4936-80cd-688471c8d9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158368"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/curso_word2vec/BertEmbeddings/BertFinetunedWords.json\", \"w\") as f:\n",
        "  f.write(json.dumps(tokenized_text))"
      ],
      "metadata": {
        "id": "s7iKTSTJblSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}